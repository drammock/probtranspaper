%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Algorithms for Training ASR Using Probabilistic Transcription}
%% from the point of view of the flow of data, it seems like section 
%% 4 (about generating PTs) should come before this section (which is
%% about adapting existing ASR system designs to use PTs)
% Good idea!  Done.


An automatic speech recognizer (ASR) is a parameterized probability
mass function, $\pi(x,s|\phi,\theta)$, specifying the dependence of
acoustic features, $x$, and senones, $s$, on the phone transcription
$\phi$ and the parameter vector $\theta$, where the notation
$\pi(\cdot)$ denotes a pmf dependent on the ASR parameter vector.  
Assume a hidden Markov model~\cite{Baker75}, therefore
\[
\pi(x,s|\phi,\theta)=\prod_{\ell=1}^L \prod_{t=1}^T
\pi(s_t^\ell|s_{t-1}^\ell,\phi^\ell,\theta)\pi(x_t^\ell|s_t^\ell,\phi^\ell,\theta)
\]
