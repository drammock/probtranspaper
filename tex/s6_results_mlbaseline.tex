\subsection{Cross-Lingual Baseline}
\label{s6:mlbaseline}

The first four columns of Table~\ref{tab:ptresult}
compare a monolingual ASR with phone language model based on
monolingual transcripts, a 
cross-lingual ASR using universal phone set and
phone language model, and a cross-lingual ASR using a
phone language model based on language-dependent Wikipedia texts.

%Without a language specific phone set
%and phone language model, it is hard for a cross-lingual system to
%generalize to an unseen language.  This is true even if the system has
%seen closely related languages such as Mandarin when tested on
%Cantonese.  
%
%\begin{table*}
%\begin{center}
%\begin{tabular}{|c|c|c|cccc|}
%\hline
%data & acoustic & language & yue & hun & cmn & swh \\
% & model & model &  & & & \\
%\hline
%cross-lingual & GMM & cross-lingual & 79.64 (79.83) & 77.13 (77.85) & 83.28 (82.12) & 82.99 (81.86) \\
%cross-lingual & NN & cross-lingual & 78.62 (77.58) & 75.98 (76.44) & 81.86 (80.47) & 82.30 (81.18) \\
%cross-lingual & GMM & text & 68.40 (68.35) & 68.62 (66.90) & 71.30 (68.66) & 63.04 (64.73) \\
%cross-lingual & NN & text & 66.54 (65.28) & 66.08 (66.58) & 65.77 (64.80) & 64.75 (65.04) \\
%\hline
%monolingual & GMM & transcript & 32.77 (34.61) & 39.58 (39.77) & 32.21 (26.92) & 35.33 (46.51) \\
%monolingual & NN & transcript & 27.67 (28.88) & 35.87 (36.58) & 27.80 (23.96) & 34.98 (41.47) \\
%\hline
%\end{tabular}
%\vspace*{1mm}
%\caption{\label{tab:results} PERs of unadapted cross-lingual
%  and monolingual ASR on
%  the evaluation sets (development sets are in parentheses).
%  Text-based language models are
%  trained using Wikipedia.
%  Transcript-based
%  language models are based on
%  native transcripts of the training data.}
%\end{center}
%\end{table*}

The monolingual ASR is trained using only 40 minutes of audio and
transcript data per language, but performs reasonably well (31.58\%
average PER, NN-HMM).  The cross-lingual ASRs, however, perform poorly.
%From the comparison of different baseline systems, we can reach the
%following conclusions.  First, even with only 40 minutes of
%training data, a NN is able to outperform a GMM.  Second,
%however, the standard speech pipeline performs poorly on unseen languages.
Using a language-specific phonotactic language model gives
significant improvement over the language-independent phonotactic
model, but significantly underperforms a system that
has seen the test language during training.  This is true
even if the system has seen closely related languages during training:
the Cantonese cross-lingual system has seen Mandarin during training,
and the Mandarin system has seen Cantonese during training, but
neither system is able to generalize well from its six training languages to
its test language.

